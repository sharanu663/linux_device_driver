Nordic examples:
https://github.com/NordicDeveloperAcademy




The scheduler distinguishes between two types of threads based on their priority: cooperative and preemptible.
A thread with a negative priority is classified as a cooperative thread. Once a cooperative thread becomes the current thread, 
it will remain so until it performs an action that makes it unready.

On the other hand, a thread with a non-negative priority is classified as a preemptible thread.
Once a preemptible thread becomes the current thread, 
it may be replaced at any time if a cooperative thread or a preemptible thread of higher or equal priority becomes ready.

The number of non-negative priorities, which is associated with preemptible threads, 
is configurable through the Kconfig symbol CONFIG_NUM_PREEMPT_PRIORITIES and is, by default, equal to 15. 
The main thread has a priority of 0, while the idle thread has a priority of 15 by default.





Interrupt Service Routines (ISRs) are generated asynchronously by the device drivers and protocol stacks.
They are not scheduled. This includes callback functions, which are the application extension of ISRs. 
It is important to remember that ISRs preempt the execution of the current thread, allowing the response to occur with very low overhead. 
Thread execution resumes only once all ISR work has been completed. Therefore, it is important to make sure that ISRs, including callback functions, 
do not contain time-consuming work or involve blocking functionalities, as they will starve all other threads



There are two ways to create a thread in Zephyr, the first one is dynamically (at run-time) through : k_thread_create()



which is more frequently used, is statically (at compile time) by using the : K_THREAD_DEFINE() macro. 
This is the macro for defining and initializing a thread and plugging its data structures into the RTOS kernel,


#define STACKSIZE 1024
#define THREAD0_PRIORITY 7
#define THREAD1_PRIORITY 7

extern const k_tid_t thread0_id;
extern const k_tid_t thread1_id;
extern void my_entry_point(void *,void *,void*);

extern void my_entry_point(void *,void *,void*){
      printk("Hello, I am thread0\n");
}


extern void my_entry_point_two(void *,void *,void*){
      printk("Hello, I am thread1\n");
}

K_THREAD_DEFINE(thread0_id, STACKSIZE, thread0, NULL, NULL, NULL,
		THREAD0_PRIORITY, 0, 0);
K_THREAD_DEFINE(thread1_id, STACKSIZE, thread1, NULL, NULL, NULL,
		THREAD1_PRIORITY, 0, 0);

parameters :

name: The name of the thread.

stack_size: Size of the stack in bytes.

entry: The function the thread will execute (thread entry point).

p1, p2, p3: Optional parameters passed to the entry function.

prio: Thread priority (lower values are higher priority).

options: Thread options (e.g., K_ESSENTIAL, K_FP_REGS, etc.), can be combined using |.

delay: Delay (in milliseconds) before the thread starts running. 0 means immediate start.



If Two thread as same priority and there is no k_sleep() or k_msleep() function on both threads,What will happen
thread1 will not get chance to execute. In this situtaion either use sleep() function or 
k_yield().

Lets usage of k_yield() : thread0 and thread1 voluntarily yield using. it means 
causes the current thread to give away execution (yield) to another thread of the same or higher priority.
 
extern void my_entry_point(void *,void *,void*){
      printk("Hello, I am thread0\n");
      k_yield();
}


extern void my_entry_point_two(void *,void *,void*){
      printk("Hello, I am thread1\n");
      k_yield();
}


The disadvantage of this is that yielding this often and thereby invoking the scheduler also takes up CPU time. 
The scheduler uses CPU time to do the book-keeping of the kernel resources every time k_yield() is called which in turn costs power. 
A system with good architecture entails designing your threads so the scheduler uses a minimal amount of CPU time,
i.e designing threads that have correct priorities and are reasonably considerate (yielding/sleeping/waiting) to other threads.



To enable the time slicing : we to mention MACRO in prj.conf file.
CONFIG_TIMESLICING=y
CONFIG_TIMESLICE_SIZE=10
CONFIG_TIMESLICE_PRIORITY=0

TIMESLICING : enables the time slicing feature.

TIMESLICE_SIZE : is the maximum time (in ms) that the current running thread has before 
it is forcefully preempted by the scheduler to allow the other equal priority threads to run.

TIMESLICE_PRIORITY : is the priority threshold for time slicing,meaning threads with higher priority 
than this threshold are not subject to time slicing. 
We set this value to 0. This means priorities (0 to 15) will be affected by time-slicing only 
when two or more threads exist in one level. 
It’s always important to remember that time slicing only affect threads with the same priority level.





Workqueue: A workqueue in Zephyr is essentially a dedicated thread with additional features. 
It's designed to execute functions (work items) that have been submitted to it in a first-in, first-out (FIFO) manner

Workqueues are particularly useful for handling tasks that are triggered by interrupts 
but require more processing time than an ISR can afford to spend.
By submitting the task to a workqueue, the ISR can quickly return, and the workqueue 
thread will handle the actual processing later. 

ex: we created two thread, thread0 has high priority, observ the both thread doing same work 
and emulate_work() is inline function.the execution of thread0 it will take 23 msec but thread1
it will taking execution time double becuase of preempted by the thread0.we can avoid the thread0
is processing non-urgent work using "workqueue".




#define THREAD0_PRIORITY 2 
#define THREAD1_PRIORITY 3
#define WORKQ_PRIORITY   4


void thread0(void)
{
    uint64_t time_stamp;
    int64_t delta_time;

    while (1) {
        time_stamp = k_uptime_get();
        emulate_work();
        delta_time = k_uptime_delta(&time_stamp);

        printk("thread0 yielding this round in %lld ms\n", delta_time);
        k_msleep(20);
    }   
}

void thread1(void)
{
    uint64_t time_stamp;
    int64_t delta_time;

    while (1) {
        time_stamp = k_uptime_get();
        emulate_work();
        delta_time = k_uptime_delta(&time_stamp);

        printk("thread1 yielding this round in %lld ms\n", delta_time);
        k_msleep(20);
    }   
}

static inline void emulate_work()
 
{
	for(volatile int count_out = 0; count_out < 300000; count_out ++);
}

Output:
*** Booting nRF Connect SDK ***
*** Using Zephyr OS ***
thread0 yielding this round in 23 ms
thread0 yielding this round in 24 ms
thread1 yielding this round in 50 ms
thread0 yielding this round in 23 ms
thread0 yielding this round in 23 ms
thread1 yielding this round in 50 ms


after modified the above code:
Offloading work from high priority task of thread0

Since thread0 is processing non-urgent work,
it is not good practice to block other threads just to perform this work. 
Let’s offload the non-urgent emulate_work() into a lower priority workqueue thread.

We need to associate our work (emulate_work()) as a work item and push it to a specific workqueue. 
This is done by creating a work_info structure and a function, 
offload_function() that should only run emulate_work().

struct work_info {
    struct k_work work;
    char name[25];
} my_work;

void offload_function(struct k_work *work_term)
{
	emulate_work();
}

In the entry function for thread0, start the workqueue using k_work_queue_start(). 
Then initialize the work item using k_work_init() to connect the work item to its handler offload_function().
k_work_queue_start(&offload_work_q, my_stack_area,
                   K_THREAD_STACK_SIZEOF(my_stack_area), WORKQ_PRIORITY,
                   NULL);

strcpy(my_work.name, "Thread0 emulate_work()");
k_work_init(&my_work.work, offload_function);

Instead of running emulate_work in the while-loop, 
submit a work item to the workqueue using k_work_submit_to_queue()

k_work_submit_to_queue(&offload_work_q, &my_work.work);

OUTPUT:
*** Booting nRF Connect SDK ***
*** Using Zephyr OS ***
thread0 yielding this round in 0 ms
thread0 yielding this round in 0 ms
thread1 yielding this round in 26 ms
thread0 yielding this round in 0 ms
thread0 yielding this round in 0 ms
thread1 yielding this round in 26 ms
thread0 yielding this round in 0 ms
thread0 yielding this round in 0 ms










k_sleep() : use for delay 
k_wakeup() : A sleep thread can be woken up prematurely  by another thread using 
k_busy_wait() : uses for current theread still not yet completed within time period.
we are telling the CPU don't do context switch perform.

A busy wait is typically used instead of thread sleeping when required delay is too short to
warrant having the scheduler context switch from the current thread to another thread and 
then back again.

k_sched_lock() : when currect thread performing  critical operation and we does not 
wish to be preempted another theread, we are telling scheduler to temporarily treat it as
cooperative theread.

Once the critical operation is complete the preemptible thread must call "k_sched_unlock()".

k_cpu_idle() : making the cpu idle is simple.the cpu stop executing insteructions unitl an even occurs

ex:   static k_sem my_sem;

void my_isr(void *unused)
{
  k_sem_give(&my_sem);
}

int main()
{
  k_sem_init(&my_sem,0,1);
  for(;;){
    if(k_sem_take(&my_sem,K_NO_WAIT) == 0) {
    }
    k_cpu_idle();
  }
}

k_cpu_atomic_idle(): above example have race conition, the interrupt could occur b/w the 
time the semaphore is taken, finding out it is not available and making the CPU idle again.
this can cause the CPU to idle unitl another interrupt occurs, which might be never, thus hanging
the system completely.To prevent this, k_cpu_atomic_idle() use.

ex:   static k_sem my_sem;

void my_isr(void *unused)
{
  k_sem_give(&my_sem);
}

int main()
{
  k_sem_init(&my_sem,0,1);
  for(;;){

     unsigned int key = irq_lock();
    if(k_sem_take(&my_sem,K_NO_WAIT) == 0) {
          irq_unlock(key);
    }
    else {
    k_cpu_atomic_idle(key);
  }
}


K_NO_WAIT: means to start the thread immediately. the corresponding parameter to K_THREAD_DEFINE is a
duration in integral milliseconds, so the equivalent to argument is 0.

statically create task : 

#define MY_STACK_SIZE 500
#deifine MY_PRIORITY 5

extern void my_entry_point(void *,void *,void*);

K_THREAD_STACK_DEFINE(my_stack_area,MY_STACK_SIZE);
struct k_thread my_thread_data;

k_tid_t my_tid = k_thread_create(&my_thread_data, my_stack_area,K_THREAD_STACK_SIZEOF(my_stack_area),
                                  my_entry_point, NULL,NULL,NULL,MY_PRIORITY,0,K_NO_WAIT);


or  
#define MY_STACK_SIZE 500
#deifine MY_PRIORITY 5

extern void my_entry_point(void *,void *,void*);
K_THREAD_DEFINE(my_tid,MY_STACK_SIZE,my_entry_point,NULL,NULL,NULL,,MY_PRIORITY,0,0);





dynamically allocates a thread stack:

#define MY_STACK_SIZE 500
#deifine MY_PRIORITY 5

extern void my_entry_point(void *,void *,void*);
k_tid_t my_tid;
void *my_stack_area;
my_stack_area = k_thread_stack_alloc(CONFIG_DYNAMIC_THREAD_STACK_SIZE);
my_tid = k_thread_create(&my_thread_data, my_stack_area,CONFIG_DYNAMIC_THREAD_STACK_SIZE,
                                  my_entry_point, NULL,NULL,NULL,MY_PRIORITY,0,K_NO_WAIT);
k_thread_join(my_tid,K_FOREVER);
k_thread_stack_free(my_stack_area);












